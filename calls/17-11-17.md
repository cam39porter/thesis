
Developing content around it but focus on the systems architecture. Copy Greg on the email. 

We don't want him to feel like he is running away with this

Working with people at Maxwell Stamp to develop framework. Conceptual framework that is schematic. Develop a visual representation for analytical approach.

Summary statement that is our conceptual framework.

Taxonomy what are the components or types of data we are going to be using.

Mathematical expression of the taxonomy that is the algorithm.

We are developing the framework and taxonomy with Stamp. Integrate into the thesis and the thesis architecture.

Data sources are what I have instead of datasets or data types.

Abstract using data ranging from rents and property value and types of coffee shops and infrastructure measures that include bike lanes. 

Give people the sense that it is creative and different.

Here are 200 of the indicators we are using for this problem.

How can you autogenerate common indicators (common ratios)

Do you want number of starbucks per age segment or per capita or population density.

What is that we are really trying to measure

Very unlikely that we are going to be using the raw data. We are going to have to standardize and normalize these to use them.

Is there a way to pull in data from the original source and pull in new data. Add layer that pings sources for new data and can update.

Virtualized database has value as it well. People don't want to work with data they actually want to work with data products.

People want quantitatively measure. If you can meausre it you cant improve it. 

Form an index of indicators. Throw out profressional scientific type metrics are done in a transparent fashion on data is openly available and that the results are reproducible.

In terms of bringing this into an operational capability. Because we are modeling where these markets will be best. We want to evaluate how successful we are. We want to incorporate the learning process and have feedback into the system. We want to the performance is being measured and be improved. Brompton you are going to go here and be able to sell X bikes, but they say we sold Y bikes. Sense that this is not locked down in a black box. Results in porbabilistic terms with confidence levels.

We don't have calibration data to check whether our outputs are really true. You can sell this many bikes at this confidence. We want to run this against known locations selling Brompton bikes. Hindcasting. You run it for something where you know your results in order update your model.

Give sense living alrogithm. providing in each of these layers should there be an interface there that allows them to play with the dev of new indicators. (This is already there)

We would be happy with correlations R values of .3 instead of .4. Can we dial down the statistical.

Copy greg on the email and he would be happy to call him